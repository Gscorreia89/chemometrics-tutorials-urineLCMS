{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimination of biological sex from urinary metabolic profiles using Partial Least Squares – Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use a PLS-DA classifier model to discriminate urine biofluid metabolic profiles based on the participant's sex. \n",
    "\n",
    "The notebook is divided in the following steps:\n",
    "\n",
    "1) Model fitting basics: Fit a PLS-DA model to predict biological sex from the metabolic profile data, using different types of scaling.\n",
    "2) Model cross-validation and parameter selection: Describe model cross-validation, robust parameter selection with double-cross validation and performance assessment for a PLS-DA model.\n",
    "\n",
    "3) Model interpretation: Inspect the variables which contribute more to the discrimination and highlight which variables seem different between males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required python packages including \n",
    "# the custom Chemometric Model objects\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pds\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "\n",
    "from pyChemometrics.ChemometricsPLSDA import ChemometricsPLSDA\n",
    "from pyChemometrics.ChemometricsPCA import ChemometricsPCA\n",
    "from pyChemometrics.ChemometricsPLS import ChemometricsPLS\n",
    "from pyChemometrics.ChemometricsScaler import ChemometricsScaler\n",
    "from pyChemometrics.plotting_utils import _scatterplots\n",
    "\n",
    "\n",
    "# Use to obtain same values as in the text\n",
    "np.random.seed(350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell sets up the figure display mode. The *notebook* mode allows interactive plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot backend to support interactive plotting\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now import the LC-MS RPOS Dementia  dataset together with metadata required for this example.\n",
    "\n",
    "rpos_x_matrix - LC-MS data matrix, with observations in rows and features as columns. The data has already been normalised by probabilistic quotient normalization to account for variation in urinary dilution.\n",
    "\n",
    "variable_names - Unique names for each LC-MS feature. Each id is a concatenation of retention time (in seconds) and m/z (retentionTime_m/z)\n",
    "\n",
    "#### Metadata\n",
    "Gender - Biological sex of the participants (Male or female)\n",
    "\n",
    "Age - Age of the study participants, in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dementia_rpos_dataset = pds.read_csv(\"./Data/Dementia_RPOS_XCMS.csv\",delimiter=',')\n",
    "\n",
    "rpos_x_matrix = dementia_rpos_dataset.iloc[:, 13::].values\n",
    "\n",
    "variable_names = dementia_rpos_dataset.columns[13::]\n",
    "# Use pandas Categorical type\n",
    "gender_y = pds.Categorical(dementia_rpos_dataset['Gender']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the retention times and m/z to use in 2D plots of the dataset\n",
    "retention_times = np.array([x.split('_')[0] for x in variable_names], dtype='float')/60\n",
    "mz_values = np.array([x.split('_')[1][0:-3] for x in variable_names], dtype='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: To apply the analyses exemplified in this notebook to any other dataset, just modify the cell above to import the data matrices and vectors X and Y from any other source file.\n",
    "\n",
    "The expected data types and formatting for **X** and **Y** are:\n",
    "\n",
    "   **X**: Any data matrix with n rows (observations/samples) and p columns (variables/features). The matrix should be provided as a [numpy.ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) object, with 2 dimensions, and with shape = (n, p). We recommend using the *numpy* function [numpy.genfromtxt](https://numpy.org/devdocs/reference/generated/numpy.genfromtxt.html) or the *pandas* [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) function to read the data from a text file. When using the *pandas.read_csv* function, extract the data matrix as a *numpy.ndarray* from the pandas.DataFrame object using the `.values` attribute. \n",
    "```\n",
    "X_DataFrame = pds.read_csv(\"./data/X_spectra.csv\")\n",
    "X = X_DataFrame.values\n",
    "```\n",
    "   \n",
    "   **Y** vectors: Each **Y** vector should be a 1-dimensional [numpy.ndarray](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) object, with a number and ordering of elements matching the rows in **X**. For continuous variables, any regular *numpy.ndarray* with a data type of `int` (integers only) or `float` can be used.\n",
    "   ```\n",
    "   Y_continuous = numpy.ndarray([23.4, 24, 0.3, -1.23], dtype='float')\n",
    "   ```\n",
    "To handle class labels, we recommend using the *pandas* [Categorical](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) datatype. After converting a column to a `Categorical` datatype, the `.codes` attribute returns a vector with the same length of the original Y, but where each value is replaced by their integer (`int`) code. The correspondence between code and category can be inspected with the `categories` attribute. The order of the labels in `.codes` is the same as the order of the `categories` attribute (i.e. 0 is the first element in `categories`, 1 the second and so on).\n",
    "   ```\n",
    "   Y1 = pds.Categorical(Y.iloc[:, 1])\n",
    "   Y1.codes # The numerical label\n",
    "   Y1.categories # Original text or numerical description of the category\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the spectra in the dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the dataset \n",
    "\n",
    "The next cell will plot in 2-dimensions (retention time and m/z) the features on the reversed phased positive (RPOS) LC-MS dataset. High resolution LC-MS datasets are very complex, with numbers of features routinely exceeding > 10,000. Visualization of the raw dataset or even derived peak picked data sets is not straightforward. 2D scatter plots, such as the one shown below can be used to project quantities, of interest from multivariate and machine learning models, to get an overview of the co-elution patterns and m/z ranges from the detected signatures.\n",
    "\n",
    "**Note**: 2D scatterplots contain a large number of datapoints. We recommend closing the plot after inspection by using the \"power\" button in the top right corner of the figure frame, to avoid performance issues when opening multiple plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the spectra in the dataset\n",
    "from pyChemometrics.plotting_utils import _scatterplots\n",
    "# Helper 2D plot function from pyChemometrics\n",
    "_scatterplots(np.log(np.mean(rpos_x_matrix, axis=0) + 1), xaxis=retention_times, yaxis=mz_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS-DA modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model fitting basics\n",
    "\n",
    "In this section we will fit a PLS-DA model to classify urine LC-MS metabolic profiles based on the individual biological sex, and assess the metabolic differences in urine samples from males and females.\n",
    "\n",
    "As an example, we start by fitting a PLS-DA model with 2 components and with mean-centring (MC) scaling. The choice of components to use in the modeling will be addressed properly in the next section, the objective of this first section is to introduce the model syntax.\n",
    "\n",
    "Before mean centring, we will log-transform the data. One advantage of using log-transform in large and complex datasets is the effect log-transforming variables has on extreme (outlying values). After log-transformation, the impact of outliers on the fitted models (leverage) decreases []()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the scaling options: \n",
    "offset = np.min(rpos_x_matrix) + 1\n",
    "log_X = np.log(rpos_x_matrix + offset)\n",
    "\n",
    "# Mean centring (MC) scaling:\n",
    "scaling_object_mc = ChemometricsScaler(scale_power=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit PLS-DA model\n",
    "pls_da = ChemometricsPLSDA(n_components=2, x_scaler=scaling_object_mc)\n",
    "pls_da.fit(log_X, gender_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLS models perform dimensionality reduction in a manner similar to PCA. The main difference (besides the criteria in which the components are found) is that as well as the projections for the X matrix ($T$ scores) we also have projections for the Y matrix ($U$ scores).\n",
    "\n",
    "Model visualization of PLS/PLS-DA models is typically performed by plotting the $T$ scores (X matrix scores). \n",
    "The score plot gives an overview of the relationships between samples, their similarities and dissimilatrities within the model space.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Warning**: PLS-DA models can easily overfit, and the degree of separation or clustering of samples from distinct classes or Y outcome in the score plot is not a reliable measure of model validity. We recommend focusing on model validation before exploring the relationships in the scores plot. See the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the scores\n",
    "pls_da.plot_scores(color=gender_y, discrete=True, label_outliers=True, plot_title=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the loadings, weights and other model parameters are less straightforward in LC-MS datasets. We suggest using 2D scatterplots or barplots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_da.plot_model_parameters(parameter='w', component=1, plottype='scatterplot', xaxis=retention_times, yaxis=mz_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the weights and loadings.\n",
    "# w for weights, p for loadings,\n",
    "# ws for X rotations (rotated version of w) \n",
    "pls_da.plot_model_parameters(parameter='VIP', component=1, plottype='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model Selection - Number of components\n",
    "\n",
    "Selection of the number of components for a PLS model follows a very similar logic to the PCA case.\n",
    "Since the goal is to predict the Y variable, the main criteria used are the $R^{2}Y$/$Q^{2}Y$ as opposed to $R^{2}X$/$Q^{2}X$. \n",
    "\n",
    "However, the $R^{2}Y$/$Q^{2}Y$ measures are suited for regression problems, and not easily interpretable in classification problems. Metrics adequate for classification problems, such as accuracy or the Receiver-Operating Curve Area Under the Curve (ROC AUC) are more adequate in this context.\n",
    "\n",
    "Ideally, we want to select enough components to predict as much of the variation in Y as possible using the data in X, while avoiding overfitting. \n",
    "\n",
    "We apply a similar criterion as the one used with PCA: choosing as the number of components after which the $Q^{2}Y$ or AUC value reaches a plateau (less than 5% increase compared to previous number of components). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pls_da.scree_plot(log_X, gender_y, total_comps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this dataset has a large number of observations (561), we can further improve the robustness of the parameter selection and model evaluation by using a nested or [double cross-validation scheme](https://link.springer.com/article/10.1007/s11306-011-0330-3).\n",
    "\n",
    "In a nested, or double cross-validation scheme the data is first split into a training and a test set, in an \"outer\" cv loop. The test set is kept aside. Then, the training test is used to optimize the model parameters. These are optimized not by taking the entire training set and fitting the model, but by using an \"inner\" cv loop, where the initial training data is again partitioned into independent training and test sets. Models with varying parameters are fitted in the \"inner\" training sets, and their performance benchmarked in the \"inner\" cv loop test sets. Then, parameters which give the best performance are selected, a model fitted on the entire training set. This model is tested on the test set kept aside in the \"outer\" cv loop. \n",
    "\n",
    "**Note**: Model cross-validation, especially *double cross validation* such as the one executed in the next cell requires fitting the model multiple times, and can take a few minutes. For reference, execution of the next cell takes (pproximately 15 mins on a desktop PC with 8 cores).\n",
    "13min 7s ± 13.7 s per loop (mean ± std. dev. of 7 runs, 1 loop each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeated cross_validation\n",
    "double_CvModel = pls_da.double_cross_validation(log_X, gender_y, total_comps=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model \n",
    "Inspect the model obtained using the number of components selected by double cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "double_CvModel.plot_scores(color=pds.Categorical(dementia_rpos_dataset['Gender']).codes, discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of components selected by double cross-validation: {0}\".format(double_CvModel.n_components))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain more reliable estimates we can calculate the cross-validation estimates of any of these metrics, including cross-validated ROC curves. This ROC curve was estimated using the left-out samples (the test sets) during cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validated ROC curve\n",
    "double_CvModel.cross_validation(log_X, gender_y)\n",
    "double_CvModel.plot_cv_ROC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Testing\n",
    "A final and very important method for model validation is the permutation randomization test. In a permutation randomisation test, the model will be refitted and assessed multiple times, but each time with the Y randomly permuted to destroy any relationship between X & Y. This allows us to assess what sort of model we can get when there really is no relationship between the two data matrices, and calculate the likelihood of obtaining a model with predictive performance as good as the non-permuted model by chance alone.\n",
    "\n",
    "During this test, the number of components, scaling, type of cross-validation employed, and any other modeling choice is kept constant. In each randomization, the model is refitted, and the AUC, $Q^{2}Y$ or any other validation metric is recorded. This enables the generation of permuted null distributions for any parameter, which can be used to obtain an empirical *p-value* for their significance.\n",
    "\n",
    "**Note** Running the permutation test with a large number of permutation randomizations (for example, 1000) is expected to take a considerable ammount of time and might require leaving the computations running overnight (approximately 8h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "permt = double_CvModel.permutation_test(log_X, gender_y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results from the permuation test\n",
    "double_CvModel.plot_permutation_test(permt, metric='AUC')\n",
    "plt.xlabel('AUC')\n",
    "plt.ylabel('Counts')\n",
    "print(\"Permutation p-value for the AUC: {0}\".format(permt[1]['AUC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *p-value* obtained is < 0.05, so the model AUC and Q2Y values are significantly different from what is expected by chance alone at a level of $\\alpha$ = 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model interpretation and variable importance\n",
    "\n",
    "The main parameters to assess in terms of variable importance for the prediction of Y from X are the weights ($w$), the VIP metric and regression coefficients.\n",
    "\n",
    "The values in a weight vector vary between -1 (strong negative-covariance) and 1 (strong covariance), with 0 meaning no association/covariance. The weight vector of the first component (which explains the most variation in Y) is the primary weight vector to analyze when interpreting the main variables of X associed with Y.\n",
    "\n",
    "The variable importance for prediction (VIP) metric is a sum (weighted by the ammount of variance of Y explained by each respective component) of the squared weight values. It provides a summary of the importance of a variable accounting for all weight vectors. VIPs are bounded between 0 (no effect) and infinity. Because it is calculated from the weights $w$, for PLS models with a single component these are directly proportional to the $w^{2}$. The VIP metric has the disadvantage of pooling together $w$ vectors from components which contribute a very small magnitude to the model's $R^{2}Y$.\n",
    "\n",
    "The regression coefficients ($\\beta$) have a similar interpretation as regression coefficients in a multivariate/multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters and their cross-validated errors (standard deviation) to a file.\n",
    "variableSelectionResults = pds.DataFrame(np.c_[variable_names, double_CvModel.weights_w[:, 0], double_CvModel.VIP(), double_CvModel.beta_coeffs, \n",
    "                                               double_CvModel.cvParameters['Stdev_Weights_w'][:, 0], double_CvModel.cvParameters['Stdev_VIP'], \n",
    "                                               double_CvModel.cvParameters['Stdev_Beta'].squeeze()], columns=['Feature Name', 'Weights_w - PLS Component 1', 'VIP', 'Beta', 'StDev_W', 'StDev_VIP', 'StDev_Beta'])\n",
    "variableSelectionResults.to_csv('./Data/LC_MS_PLSDA_VarImportance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_CvModel.plot_model_parameters('w', component=1, plottype='scatterplot', \n",
    "                                     xaxis=retention_times, yaxis=mz_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double_CvModel.plot_model_parameters('VIP', plottype='scatterplot', \n",
    "                                    xaxis=retention_times, yaxis=mz_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "double_CvModel.plot_model_parameters('beta', plottype='scatterplot', \n",
    "                                    xaxis=retention_times, yaxis=mz_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation p-values for variable ranking\n",
    "\n",
    "The permutation test we ran before is also useful to obtain permuted null distributions for most of the model parameters. These can be used to obtain empirical confidence intervals and potentially permutation *p-values* for hypothesis testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate empirical p-values for the regression coefficients..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always set *nperms* equal to the number of permutations used before\n",
    "nperms = permt[0]['R2Y'].size\n",
    "perm_indx = abs(permt[0]['Beta'].squeeze()) >= abs(double_CvModel.beta_coeffs.squeeze())\n",
    "counts = np.sum(perm_indx, axis=0)\n",
    "beta_pvals = (counts + 1) / (nperms + 1)\n",
    "\n",
    "perm_indx_W = abs(permt[0]['Weights_w'][:, :, 0].squeeze()) >= abs(double_CvModel.weights_w[:, 0].squeeze())\n",
    "counts = np.sum(perm_indx_W, axis=0)\n",
    "w_pvals = (counts + 1) / (nperms + 1)\n",
    "\n",
    "perm_indx_vip = abs(permt[0]['VIPw']) >= abs(double_CvModel.VIP())\n",
    "counts = np.sum(perm_indx_vip, axis=0)\n",
    "vip_pvals = (counts + 1) / (nperms + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(r\"p-value distribution for the regression coefficients $\\beta$ \")\n",
    "z = plt.hist(beta_pvals, bins=100, alpha=0.8)\n",
    "plt.axvline(x=0.05, ymin=0, ymax=max(z[0]), color='r', linestyle='--') \n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(r\"p-value distribution for the weights corresponding to the first component\")\n",
    "z = plt.hist(w_pvals, bins=100, alpha=0.8)\n",
    "plt.axvline(x=0.05, ymin=0, ymax=max(z[0]), color='r', linestyle='--') \n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(r\"p-value distribution for the VIPw\")\n",
    "z = plt.hist(vip_pvals, bins=100, alpha=0.8)\n",
    "plt.axvline(x=0.05, ymin=0, ymax=max(z[0]), color='r', linestyle='--') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and use the permutation test to obtain a list of statistically significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signif_bpls_idx = np.where(beta_pvals <= 0.05)[0]\n",
    "\n",
    "print(\"Number of significant values: {0}\".format(len(signif_bpls_idx)))\n",
    "\n",
    "signif_bpls_idx = np.where(vip_pvals <= 0.05)[0]\n",
    "\n",
    "print(\"Number of significant values: {0}\".format(len(signif_bpls_idx)))\n",
    "\n",
    "signif_bpls_idx = np.where(w_pvals <= 0.05)[0]\n",
    "\n",
    "print(\"Number of significant values: {0}\".format(len(signif_bpls_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that a selection procedure of this kind is also a type of multiple testing, and it is recommended to apply false discovery rate or any other multiple testing correction to the *p-values* obtained in this manner. Also, formal inferential procedures to derive *p-values* and confidence intervals are not established for PLS models. Although *ad-hoc* solutions like a permutation test can be implemented as shown, some issues still remain - for example, the *p-value* distribution obtained for the regression coefficients is clearly non-uniform and care must be exercised when performing multiple testing correction or even interpreting the *p-values* obtained in this manner.\n",
    "\n",
    "The latent variable and dimensionality reduction provided by PLS/PLS-DA can be very usefull to visualize general trends in the data. However, interpreting which variables are important to the model and how they contribute for the explanation/separation between classes is not easy. We suggest complementing the inspection of multivariate model parameters with univariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
